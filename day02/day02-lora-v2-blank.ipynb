{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Large Language Model - Model\n",
    "\n",
    "In this workshop, you will learn how to fine tune the prompts and the LLMs to enhance and improves its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, GenerationConfig, TrainingArguments\n",
    "\n",
    "from peft import PeftModel, LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
      "        num_rows: 12460\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
      "        num_rows: 1500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load and explore the following datasets\n",
    "\n",
    "dataset_name = \"knkarthick/dialogsum\"\n",
    "model_name = \"google/flan-t5-small\"\n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "# load dataset\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# print dataset\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': (12460, 4), 'validation': (500, 4), 'test': (1500, 4)}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print a record\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "train_5000\n",
      "\n",
      "dialogue\n",
      "#Person1#: do you like animals? I really like dogs.\n",
      "#Person2#: so do i. I don't like cats.\n",
      "#Person1#: why? I think cats are ok.\n",
      "#Person2#: I can't bear being near cats. They don't seem to like me either.\n",
      "#Person1#: I like wild animals. I don't like spiders and snakes. I think spiders and snakes are disgusting.\n",
      "#Person2#: I'm fond of snakes. I think they're great. I agree with you about spiders though. I think spiders are horrible. I think it's because they have so many legs.\n",
      "#Person1#: I think bears are wonderful. Pandas are fantastic. I low the people who kill them for their fur.\n",
      "#Person2#: I agree. I'm carry about mice. I think they're so cute!\n",
      "#Person1#: really? I don't see the attraction. I'm afraid of mice.\n",
      "\n",
      "summary\n",
      "#Person1# likes dogs, wild animals but doesn't like spiders and snakes. #Person2# doesn't like cats but likes snakes and mice.\n",
      "\n",
      "topic\n",
      "animals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a record\n",
    "idx = 5000\n",
    "\n",
    "for k, v in dataset['train'][idx].items():\n",
    "   print(k)\n",
    "   print(v)\n",
    "   print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the LLM model\n",
    "\n",
    "In this workshop we will be turning the <code>google/flan-t5-base</code> model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to dump a model's tunable parameters\n",
    "\n",
    "def print_trainable_model_params(model):\n",
    "   trainable_model_params = 0\n",
    "   all_model_params = 0\n",
    "   for _, param in model.named_parameters():\n",
    "      all_model_params += param.numel()\n",
    "      if param.requires_grad:\n",
    "         trainable_model_params += param.numel()\n",
    "   return f\"Trainable parameters: {trainable_model_params}\\nTotal parameters: {all_model_params}\\nPercentable of trainable parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load model\n",
    "orig_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 247577856\n",
      "Total parameters: 247577856\n",
      "Percentable of trainable parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print number of trainable parameters\n",
    "print(print_trainable_model_params(orig_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the dialogue dataset\n",
    "\n",
    "We will train the model to summarize dialogue by creating a dialogue-summary pair for the LLM to process. The dialogue is the training data and the summary is the label. This is supervized learning.\n",
    "\n",
    "The prompt will be as follows\n",
    "\n",
    "```\n",
    "Summarize the following dialogue.\\n\n",
    "\\n\n",
    "Fred: ...\\n\n",
    "Barney: ...\\n\n",
    "\\n\n",
    "Summary:\\n\n",
    "Summary of the conversation between Fred and Barney\n",
    "```\n",
    "\n",
    "The prompt and the summary will be tokenized for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utitlity function to prepare the data for training \n",
    "# Tokenize function\n",
    "def tokenize_fn(data):\n",
    "   start_prompt = 'Summarize the following dialogue.\\n\\n'\n",
    "   end_prompt = '\\n\\nSummary:'\n",
    "   prompt = [ start_prompt + d + end_prompt for d in data['dialogue'] ]\n",
    "   summary = data['summary']\n",
    "   data['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "   data['labels'] = tokenizer(summary, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "   return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb754e6a6d7448b94d38fe54ef7851a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: prepare the data for training with the tokenize_fn function\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'labels'],\n",
      "        num_rows: 12460\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'labels'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'labels'],\n",
      "        num_rows: 1500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# TODO: Verify prepared data\n",
    "print(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "test_33_2\n",
      "\n",
      "dialogue\n",
      "#Person1#: OK, that's a cut! Let's start from the beginning, everyone.\n",
      "#Person2#: What was the problem that time?\n",
      "#Person1#: The feeling was all wrong, Mike. She is telling you that she doesn't want to see you any more, but I want to get more anger from you. You're acting hurt and sad, but that's not how your character would act in this situation.\n",
      "#Person2#: But Jason and Laura have been together for three years. Don't you think his reaction would be one of both anger and sadness?\n",
      "#Person1#: At this point, no. I think he would react the way most guys would, and then later on, we would see his real feelings.\n",
      "#Person2#: I'm not so sure about that.\n",
      "#Person1#: Let's try it my way, and you can see how you feel when you're saying your lines. After that, if it still doesn't feel right, we can try something else.\n",
      "\n",
      "summary\n",
      "#Person1# and Mike have a disagreement on how to act out a scene. #Person1# proposes that Mike can try to act in #Person1#'s way.\n",
      "\n",
      "topic\n",
      "shooting\n",
      "\n",
      "input_ids\n",
      "[12198, 1635, 1737, 8, 826, 7478, 5, 1713, 345, 13515, 536, 4663, 10, 6902, 6, 24, 31, 7, 3, 9, 1340, 55, 1563, 31, 7, 456, 45, 8, 1849, 6, 921, 5, 1713, 345, 13515, 357, 4663, 10, 363, 47, 8, 682, 24, 97, 58, 1713, 345, 13515, 536, 4663, 10, 37, 1829, 47, 66, 1786, 6, 4794, 5, 451, 19, 5188, 25, 24, 255, 744, 31, 17, 241, 12, 217, 25, 136, 72, 6, 68, 27, 241, 12, 129, 72, 11213, 45, 25, 5, 148, 31, 60, 6922, 4781, 11, 6819, 6, 68, 24, 31, 7, 59, 149, 39, 1848, 133, 1810, 16, 48, 1419, 5, 1713, 345, 13515, 357, 4663, 10, 299, 9637, 11, 10591, 43, 118, 544, 21, 386, 203, 5, 1008, 31, 17, 25, 317, 112, 6363, 133, 36, 80, 13, 321, 11213, 11, 24784, 58, 1713, 345, 13515, 536, 4663, 10, 486, 48, 500, 6, 150, 5, 27, 317, 3, 88, 133, 8922, 8, 194, 167, 3413, 133, 6, 11, 258, 865, 30, 6, 62, 133, 217, 112, 490, 6382, 5, 1713, 345, 13515, 357, 4663, 10, 27, 31, 51, 59, 78, 417, 81, 24, 5, 1713, 345, 13515, 536, 4663, 10, 1563, 31, 7, 653, 34, 82, 194, 6, 11, 25, 54, 217, 149, 25, 473, 116, 25, 31, 60, 2145, 39, 2356, 5, 621, 24, 6, 3, 99, 34, 341, 744, 31, 17, 473, 269, 6, 62, 54, 653, 424, 1307, 5, 20698, 10, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "labels\n",
      "[1713, 345, 13515, 536, 4663, 11, 4794, 43, 3, 9, 28155, 30, 149, 12, 1810, 91, 3, 9, 3112, 5, 1713, 345, 13515, 536, 4663, 4230, 7, 24, 4794, 54, 653, 12, 1810, 16, 1713, 345, 13515, 536, 4663, 31, 7, 194, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 100\n",
    "\n",
    "for k, v in tokenized_dataset['test'][idx].items():\n",
    "   print(k)\n",
    "   print(v)\n",
    "   print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove id, dialogue, summary and topic columns from dataset. We only want input_ids and labels\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([ 'id', 'summary', 'dialogue', 'topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "[12198, 1635, 1737, 8, 826, 7478, 5, 1713, 345, 13515, 536, 4663, 10, 27, 43, 3, 9, 682, 28, 82, 4807, 5, 1713, 345, 13515, 357, 4663, 10, 363, 81, 34, 58, 1713, 345, 13515, 536, 4663, 10, 499, 4807, 65, 118, 91, 21, 8, 657, 471, 42, 78, 5, 1713, 345, 13515, 357, 4663, 10, 37, 4807, 19, 323, 269, 230, 5, 27, 183, 182, 8032, 5, 1713, 345, 13515, 536, 4663, 10, 366, 56, 34, 36, 464, 541, 58, 1713, 345, 13515, 357, 4663, 10, 94, 225, 36, 223, 30, 16, 8, 416, 1158, 13, 477, 5, 1713, 345, 13515, 536, 4663, 10, 531, 27, 341, 43, 12, 726, 21, 8, 4807, 58, 1713, 345, 13515, 357, 4663, 10, 101, 31, 60, 352, 12, 428, 25, 3, 9, 998, 298, 8, 4807, 19, 323, 5, 1713, 345, 13515, 536, 4663, 10, 264, 6, 27, 278, 31, 17, 43, 12, 726, 21, 34, 58, 1713, 345, 13515, 357, 4663, 10, 465, 6, 59, 552, 39, 4807, 639, 223, 30, 5, 1713, 345, 13515, 536, 4663, 10, 16036, 6, 2049, 21, 762, 5, 1713, 345, 13515, 357, 4663, 10, 148, 31, 60, 2222, 6, 11, 27, 22103, 21, 8, 25741, 5, 20698, 10, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "labels\n",
      "[1713, 345, 13515, 536, 4663, 65, 3, 9, 682, 28, 8, 4807, 5, 1713, 345, 13515, 357, 4663, 11236, 34, 225, 161, 541, 11, 1713, 345, 13515, 536, 4663, 744, 31, 17, 43, 12, 726, 298, 34, 31, 7, 323, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Verify dataset again\n",
    "idx = 100\n",
    "\n",
    "for k, v in tokenized_dataset['train'][idx].items():\n",
    "   print(k)\n",
    "   print(v)\n",
    "   print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune model with pre-processed dataset\n",
    "\n",
    "We will use [<code>Trainer</code>](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#api-reference%20][%20transformers.Trainer) to train the original model. The training result will be written out. The trainer will be configure with [<code>TrainingArgument</code>](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  False\n"
     ]
    }
   ],
   "source": [
    "# CUDA information\n",
    "\n",
    "print('CUDA available: ', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "   print('B16 supported: ', torch.cuda.is_bf16_supported())\n",
    "   torch.cuda.set_device(0)\n",
    "   print('Current device: ', torch.cuda.current_device())\n",
    "   print('CUDA device name: ', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the LLM Model with Low-Rank Adaptation (LoRA) / Parameter Efficient Fine Tuning (PEFT)\n",
    "\n",
    "We will add a LoRA adapter to the LLM (flan-t5-base) and train the adapter. The original LLM will be frozen. The adapter can be combined with the original LLM during inferencing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 768)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(orig_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Configure LoRA\n",
    "r = 16\n",
    "lora_config = LoraConfig(\n",
    "   r=r,\n",
    "   lora_alpha=r,\n",
    "   target_modules=['q', 'v'],\n",
    "   lora_dropout=0.05,\n",
    "   task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add LoRA to the LLM model to be trained\n",
    "lora_model = get_peft_model(orig_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1769472\n",
      "Total parameters: 249347328\n",
      "Percentable of trainable parameters: 0.71%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print number of parameters, compare LoRA to the original model\n",
    "print(print_trainable_model_params(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train model with LoRA\n",
    "lora_train_args = TrainingArguments(\n",
    "   output_dir=\"lora-train-summary\",\n",
    "   auto_find_batch_size=True,\n",
    "   learning_rate=1e-3,\n",
    "   num_train_epochs=1   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create trainer and train model\n",
    "lora_trainer = Trainer(\n",
    "   model = lora_model,\n",
    "   args = lora_train_args,\n",
    "   train_dataset= tokenized_dataset['train'],\n",
    "   eval_dataset= tokenized_dataset['validation']\n",
    ")\n",
    "\n",
    "# Start training \n",
    "lora_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a trained LoRA model\n",
    "\n",
    "The training will take a few hours and over many iterations.\n",
    "\n",
    "For the purpose of this workshop we use a save model [intotheverse/peft-dialogue-summary-checkpoint](https://huggingface.co/intotheverse/peft-dialogue-summary-checkpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 0\n",
      "Total parameters: 251116800\n",
      "Percentable of trainable parameters: 0.00%\n",
      "PeftModelForSeq2SeqLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): T5ForConditionalGeneration(\n",
      "      (shared): Embedding(32128, 768)\n",
      "      (encoder): T5Stack(\n",
      "        (embed_tokens): Embedding(32128, 768)\n",
      "        (block): ModuleList(\n",
      "          (0): T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "                  (relative_attention_bias): Embedding(32, 12)\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseGatedActDense(\n",
      "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1-11): 11 x T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseGatedActDense(\n",
      "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_layer_norm): T5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (decoder): T5Stack(\n",
      "        (embed_tokens): Embedding(32128, 768)\n",
      "        (block): ModuleList(\n",
      "          (0): T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "                  (relative_attention_bias): Embedding(32, 12)\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerCrossAttention(\n",
      "                (EncDecAttention): T5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (2): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseGatedActDense(\n",
      "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1-11): 11 x T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerCrossAttention(\n",
      "                (EncDecAttention): T5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (2): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseGatedActDense(\n",
      "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_layer_norm): T5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#TODO: Load the original model and add the pre-trained LoRA adaptation to the model\n",
    "peft_dialogue_summary_checkpoint = 'intotheverse/peft-dialogue-summary-checkpoint'\n",
    "\n",
    "lora_base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "   lora_base_model, # base model\n",
    "   peft_dialogue_summary_checkpoint, # adaptation\n",
    "   torch_dtype = torch.bfloat16,\n",
    "   is_trainable=False \n",
    ")\n",
    "\n",
    "print(print_trainable_model_params(lora_model))\n",
    "print(lora_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate LoRA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate LoRA model against the original \n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "i = 1\n",
      "i = 2\n",
      "i = 3\n",
      "i = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_model_summary</th>\n",
       "      <th>lora_model_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
       "      <td>The memo is to be distributed to all employees...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In order to prevent employees from wasting tim...</td>\n",
       "      <td>The memo is to be distributed to all employees...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
       "      <td>The memo is to be distributed to all employees...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person2# arrives late because of traffic jam....</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
       "1  In order to prevent employees from wasting tim...   \n",
       "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
       "3  #Person2# arrives late because of traffic jam....   \n",
       "4  #Person2# decides to follow #Person1#'s sugges...   \n",
       "\n",
       "                              original_model_summary  \\\n",
       "0  The memo is to be distributed to all employees...   \n",
       "1  The memo is to be distributed to all employees...   \n",
       "2  The memo is to be distributed to all employees...   \n",
       "3  The traffic jam at the Carrefour intersection ...   \n",
       "4  The traffic jam at the Carrefour intersection ...   \n",
       "\n",
       "                                  lora_model_summary  \n",
       "0  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "1  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "2  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "3  #Person2# got stuck in traffic and #Person1# s...  \n",
       "4  #Person2# got stuck in traffic and #Person1# s...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for evaluation\n",
    "dialogues = []\n",
    "summaries = []\n",
    "orig_model_summaries = []\n",
    "lora_model_summaries = []\n",
    "config = GenerationConfig(max_new_tokens=200)\n",
    "\n",
    "for i in range(5):\n",
    "   print(f'i = {i}')\n",
    "   d = dataset['test'][i]['dialogue']\n",
    "   s = dataset['test'][i]['summary']\n",
    "   prompt = f\"Summarize the following conversation.\\n\\n{d}\\n\\nSummary:\"\n",
    "   tokenized_prompt = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "   orig_resp = original_model.generate(input_ids=tokenized_prompt, generation_config=config)\n",
    "   orig_resp_text = tokenizer.decode(orig_resp[0], skip_special_tokens=True)\n",
    "   lora_resp = lora_model.generate(input_ids=tokenized_prompt, generation_config=config)\n",
    "   lora_resp_text = tokenizer.decode(lora_resp[0], skip_special_tokens=True)\n",
    "\n",
    "   summaries.append(s)\n",
    "   orig_model_summaries.append(orig_resp_text)\n",
    "   lora_model_summaries.append(lora_resp_text)\n",
    "\n",
    "zipped_summaries = list(zip(summaries, orig_model_summaries, lora_model_summaries))\n",
    "df = pd.DataFrame(zipped_summaries, columns=['label', 'original_model_summary', 'lora_model_summary'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models with ROUGE/Bleu metrics\n",
    "\n",
    "Recall-Oriented Understudy for Gisting Evaluate ([ROUGE](https://pub.aimind.so/unveiling-the-power-of-rouge-metrics-in-nlp-b6d3f96d3363)) is a set of metrics used to evaluate the quality of machine-generated text, such as summaries and translations. ROUGE metrics compare the generated text to a human-written reference and measure the overlap between the two. \n",
    "\n",
    "The metrics range between 0 and 1, with higher scores indicating higher similarity between the baseline and generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e499800b98b94a4695d38af620d3394d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: create ROUGE metrics\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the original model's result\n",
    "orig_result = rouge.compute(\n",
    "   references=summaries, # the label\n",
    "   predictions=orig_model_summaries,\n",
    "   use_stemmer=True,\n",
    "   use_aggregator=True\n",
    ")\n",
    "\n",
    "lora_result = rouge.compute(\n",
    "   references=summaries,\n",
    "   predictions=lora_model_summaries,\n",
    "   use_stemmer=True,\n",
    "   use_aggregator=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': np.float64(0.17391941391941393), 'rouge2': np.float64(0.03820816864295125), 'rougeL': np.float64(0.1301282051282051), 'rougeLsum': np.float64(0.1301282051282051)}\n",
      "--------------\n",
      "{'rouge1': np.float64(0.341935138032699), 'rouge2': np.float64(0.1024924201890494), 'rougeL': np.float64(0.2693796526054591), 'rougeLsum': np.float64(0.27097500453912726)}\n"
     ]
    }
   ],
   "source": [
    "print(orig_result)\n",
    "print('--------------')\n",
    "print(lora_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate with Bleu metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
